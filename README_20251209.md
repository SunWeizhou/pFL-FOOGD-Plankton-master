# pFL-FOOGD 项目工作记录 - 2025年12月9日

## 项目概述
pFL-FOOGD (Personalized Federated Learning with Feature-Oriented Out-of-Distribution Generalization and Detection) 是一个用于海洋浮游生物图像识别的联邦学习框架，结合了FedRoD和FOOGD技术。

## 当前状态

### 已完成的工作
1. **代码优化与修复**
   - 修复了数据泄漏问题（验证无数据泄漏）
   - 优化了KSD损失计算（添加维度归一化）
   - 改进了FOOGD模块的训练稳定性

2. **实验脚本重构**
   - 将原来的8个实验拆分为两个并行脚本
   - 创建了GPU并行运行系统
   - 优化了日志记录和实验管理

3. **数据集准备**
   - 完成了Plankton_OOD_Dataset的数据划分
   - 建立了严格的ID/Near-OOD/Far-OOD类别定义
   - 实现了非IID数据分区（Dirichlet分布）

### 当前实验配置

#### GPU 0 (4个实验)
- `alpha0.1_with_foogd` - 极端异质性 (With FOOGD)
- `alpha0.1_no_foogd`   - 极端异质性 (Baseline)
- `alpha0.5_with_foogd` - 真实强异质性 (With FOOGD)
- `alpha0.5_no_foogd`   - 真实强异质性 (Baseline)

#### GPU 1 (2个实验)
- `alpha5.0_with_foogd` - 中等异质性 (With FOOGD)
- `alpha5.0_no_foogd`   - 中等异质性 (Baseline)

### 实验参数
- **模型**: DenseNet-121
- **客户端数量**: 5
- **通信轮数**: 100
- **本地训练轮数**: 3
- **批次大小**: 64
- **图像尺寸**: 299×299
- **随机种子**: 2025（确保数据划分一致性）

## 文件结构

### 核心代码文件
- `train_federated.py` - 主训练脚本
- `models.py` - 神经网络模型定义
- `client.py` - 联邦学习客户端
- `server.py` - 联邦学习服务器
- `data_utils.py` - 数据加载和分区
- `eval_utils.py` - 评估工具

### 实验管理脚本
- `run_experiments_gpu0.sh` - GPU 0实验脚本
- `run_experiments_gpu1.sh` - GPU 1实验脚本
- `run_experiments_parallel.sh` - 并行启动脚本
- `run_experiments.sh` - 原始完整实验脚本

### 数据集相关
- `split_dataset.py` - 数据集划分脚本
- `Plankton_OOD_Dataset/` - 浮游生物OOD数据集
- `DYB-PlanktonNet/` - 原始DYB浮游生物数据集

### 测试和验证
- `test_pipeline.py` - 系统测试
- `test_foogd_pipeline.py` - FOOGD模块测试
- `verify_leakage.py` - 数据泄漏验证
- `check_overlap.py` - 数据重叠检查

### 分析和可视化
- `visualize_experiments.py` - 实验结果可视化
- `experiment_analysis_summary.md` - 实验分析总结
- `visualizations/` - 可视化结果目录
- `experiments/` - 实验输出目录

### 文档
- `CLAUDE.md` - 项目详细说明
- `README.md` - 项目主README
- `FOOGD的修正.md` - FOOGD模块修正记录
- `新项目工作文档.MD` - 项目工作文档

## 系统架构与代码功能详解

### 整体架构概述
pFL-FOOGD系统采用客户端-服务器架构，结合了FedRoD（联邦鲁棒解耦）和FOOGD（面向特征的OOD泛化与检测）技术。系统工作流程如下：

1. **数据准备阶段**: 使用`split_dataset.py`划分数据集，创建ID训练集、ID测试集、Near-OOD测试集、Far-OOD测试集
2. **客户端初始化**: 服务器创建全局模型，客户端分配非IID数据（Dirichlet分布）
3. **联邦训练循环**:
   - 服务器广播全局模型（骨干网络 + Head_G）到选定客户端
   - 客户端本地训练（Head_G + Head_P + FOOGD模块）
   - 客户端上传Head_G更新到服务器
   - 服务器聚合Head_G更新（加权平均）
4. **评估与监控**: 定期评估ID分类准确率和OOD检测性能

### 核心模块功能详解

#### 1. 模型定义模块 (`models.py`)
- **`DenseNetBackbone`类**: 基于DenseNet-121/169的特征提取器，移除最后的分类层，输出固定维度特征向量
- **`FedRoD_Model`类**: 联邦鲁棒解耦模型，包含双头架构
  - `Head_G`（通用头）: 服务器聚合，学习全局知识
  - `Head_P`（个性化头）: 客户端本地保持，学习客户端特定偏差
- **`FOOGD_Module`类**: 面向特征的OOD泛化与检测模块
  - `ScoreModel`: 轻量级评分网络，学习特征空间的梯度（对数密度梯度）
  - `compute_sm3d_loss()`: 计算Score Matching损失，结合去噪分数匹配（DSM）和最大均值差异（MMD）
  - `compute_ksd_loss()`: 计算核化Stein差异（KSD）损失，用于特征空间正则化（已优化：归一化除以特征维度）
  - `rbf_kernel_matrix()`: 计算RBF核矩阵，支持预计算距离优化
- **`create_fedrod_model()`函数**: 工厂函数，创建FedRoD模型和FOOGD模块

#### 2. 数据加载模块 (`data_utils.py`)
- **严格类别定义**: 明确定义54个ID类、26个Near-OOD类、12个Far-OOD类
- **`PlanktonDataset`类**: 支持缓存的数据集类，处理四种数据模式（train/test/near_ood/far_ood）
- **数据分区函数**:
  - `split_dataset()`: 划分原始数据集为训练集和测试集（90/10比例）
  - `create_federated_datasets()`: 使用Dirichlet分布创建非IID的客户端数据集
  - `get_class_to_indices()`: 建立类别到样本索引的映射，支持快速客户端数据采样
- **数据增强**: 支持训练时的随机裁剪、翻转、颜色抖动等增强

#### 3. 联邦学习客户端 (`client.py`)
- **`FLClient`类**: 联邦学习客户端实现
  - **初始化**: 加载本地数据集，创建本地模型副本
  - **训练流程**:
    - 使用SGD优化器训练主模型（骨干网络 + Head_G + Head_P）
    - 使用Adam优化器训练FOOGD评分模型（如果启用）
    - 计算总损失 = 分类损失 + λ_ksd * KSD损失 + λ_sm * SM损失
    - 目标lambda值：`target_lambda_ksd=0.01`, `target_lambda_sm=0.1`
  - **模型更新**: 只上传Head_G参数到服务器，Head_P保持本地化
  - **评估**: 计算本地测试集上的准确率，支持OOD检测评估

#### 4. 联邦学习服务器 (`server.py`)
- **`FLServer`类**: 联邦学习服务器实现
  - **初始化**: 创建全局模型，初始化客户端
  - **模型聚合**: 使用加权平均聚合客户端的Head_G更新，权重基于客户端样本数量
  - **通信管理**: 每轮选择部分客户端参与训练（`client_fraction`参数）
  - **检查点管理**: 定期保存模型检查点，支持训练恢复
  - **评估协调**: 协调全局模型在ID和OOD测试集上的评估

#### 5. 主训练脚本 (`train_federated.py`)
- **参数解析**: 支持丰富的命令行参数配置
- **训练循环**: 实现完整的联邦学习训练流程
  - 初始化服务器和客户端
  - 循环执行通信轮次（`communication_rounds`）
  - 每轮选择客户端，广播全局模型，收集更新，聚合模型
- **评估系统**: 定期评估并记录性能指标
  - ID分类准确率（Head_G和Head_P分别评估）
  - OOD检测性能（AUROC和FPR95，Near-OOD和Far-OOD分开计算）
- **性能优化**:
  - 预生成客户端测试加载器，避免重复创建
  - 使用`persistent_workers=True`提高数据加载效率
  - 优化KSD计算的内存使用（单次距离矩阵计算）

#### 6. 评估工具 (`eval_utils.py`)
- **综合评估函数**: 计算分类准确率、混淆矩阵、OOD检测指标
- **可视化功能**: 生成训练曲线、混淆矩阵图、OOD检测ROC曲线
- **结果分析**: 计算个性化增益（Head_P vs Head_G差异）

#### 7. 实验管理脚本
- **`run_experiments_gpu0.sh`**: GPU 0实验脚本（alpha=0.1, 0.5）
- **`run_experiments_gpu1.sh`**: GPU 1实验脚本（alpha=5.0）
- **`run_experiments_parallel.sh`**: 并行启动脚本，管理两个GPU上的实验

### 关键算法实现细节

#### FedRoD联邦学习策略
1. **模型解耦**: Head_G学习全局知识，Head_P学习客户端特定知识
2. **参数更新**: 只有Head_G参与服务器聚合，Head_P始终保持在客户端本地
3. **个性化优势**: 客户端可以使用Head_P获得更好的本地性能，同时通过Head_G获得全局知识

#### FOOGD OOD处理机制
1. **特征空间正则化**:
   - **SAG（Stein Augmented Generalization）**: 使用KSD损失对齐特征分布，提高OOD泛化能力
   - **KSD损失优化**: 损失值除以特征维度（1024/1664），与分类损失尺度匹配
2. **OOD检测**:
   - **SM3D（Score Matching）**: 训练评分模型学习特征空间的梯度
   - **检测原理**: OOD样本的评分范数（梯度大小）更大，表示密度更低
   - **评估指标**: AUROC（曲线下面积）和FPR95（95%召回率下的误报率）

#### 非IID数据模拟
- **Dirichlet分布**: 使用参数α控制数据异质性程度
  - α=0.1: 极端异质性（完全隔离站点）
  - α=0.5: 真实强异质性（典型盐度梯度差异）
  - α=5.0: 中等异质性
  - α=10.0: 接近IID（理想均匀混合）
- **客户端数据分配**: 每个客户端获得不同类别分布的样本，模拟真实世界的数据分布差异

### 代码交互流程

```
train_federated.py (主入口)
    ├── 调用 data_utils.py 创建非IID客户端数据集
    ├── 调用 models.py 创建FedRoD模型和FOOGD模块
    ├── 初始化 server.py 中的FLServer
    ├── 初始化 client.py 中的FLClient列表
    ├── 联邦训练循环:
    │   ├── server.select_clients() 选择客户端
    │   ├── client.local_train() 客户端本地训练
    │   │   ├── 训练主模型（分类损失）
    │   │   ├── 训练FOOGD模块（KSD损失 + SM损失）
    │   │   └── 更新模型参数
    │   ├── client.get_model_updates() 获取Head_G更新
    │   └── server.aggregate_updates() 聚合更新
    └── 定期调用 eval_utils.py 进行评估
```

### 性能优化特点

1. **内存优化**: KSD计算使用单次距离矩阵，减少内存占用
2. **计算优化**: 预计算类-索引映射，加速客户端数据采样
3. **I/O优化**: 数据加载器使用持久化工作进程
4. **数值稳定性**: KSD损失归一化，避免梯度爆炸
5. **可重复性**: 固定随机种子，确保实验结果可重复

## 运行指南

### 环境设置
```bash
pip install -r requirements.txt
```

### 数据集准备
```bash
python split_dataset.py
```

### 并行运行所有实验
```bash
bash run_experiments_parallel.sh
```

### 单独运行GPU实验
```bash
# GPU 0实验
./run_experiments_gpu0.sh

# GPU 1实验
./run_experiments_gpu1.sh
```

### 监控实验进度
```bash
# 查看GPU 0日志
tail -f logs/gpu0_parallel.log

# 查看GPU 1日志
tail -f logs/gpu1_parallel.log

# 查看所有实验日志
ls -la logs/*.log
```

## 关键改进点

### 1. 数据泄漏修复
- 验证了训练集和测试集之间无数据重叠
- 确保了ID、Near-OOD、Far-OOD类别的严格分离

### 2. FOOGD模块优化
- KSD损失添加了维度归一化（除以特征维度）
- 调整了目标lambda值（ksd=0.01, sm=0.1）
- 改进了训练稳定性和收敛性

### 3. 性能优化
- 预生成客户端测试加载器，避免重复创建
- 使用persistent_workers=True提高数据加载效率
- 优化了KSD计算的内存使用

### 4. 实验管理
- 创建了并行实验运行系统
- 完善的日志记录和错误处理
- 实验配置的集中管理

## 下一步计划

### 短期目标
1. 完成当前6组实验的运行
2. 分析实验结果，比较FOOGD的效果
3. 优化模型超参数

### 中期目标
1. 扩展更多alpha值的实验
2. 测试不同模型架构（DenseNet-169等）
3. 增加客户端数量和通信轮数

### 长期目标
1. 论文撰写和结果整理
2. 代码开源和文档完善
3. 扩展到其他数据集和应用场景

## 注意事项

1. **显存要求**: 建议使用NVIDIA RTX 3060（6GB VRAM）或更高
2. **数据集路径**: 确保`Plankton_OOD_Dataset`目录存在且数据完整
3. **日志监控**: 定期检查日志文件，确保实验正常运行
4. **实验重复**: 使用固定随机种子确保结果可重复

## 联系信息

- **项目负责人**: [你的姓名]
- **创建日期**: 2025年12月9日
- **最后更新**: 2025年12月9日

---

*此文档记录了pFL-FOOGD项目在2025年12月9日的状态和进展。*